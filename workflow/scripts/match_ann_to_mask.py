import pandas as pd
import json 
import logging
import pydicom
import click
import sympy.geometry as gm
import SimpleITK as sitk
import numpy as np
import matplotlib.pyplot as plt
import itertools

from damply import dirs
from pathlib import Path

def match_ann_to_image(idx_df: pd.DataFrame): 
    '''
    Takes the index file generated by MedImageTools and returns the pairs of annotation and image instances that match.
    Also logs which SRs do not have an imaging pair as well as duplicate SR ReferencedSeriesUIDs and imaging SeriesInstanceUIDs.

    Parameters 
    ----------
    idx_df: pd.DataFrame
        Contains the information found in the index.csv file 
    
    Returns 
    ----------
    matched_ann_image_df: pd.DataFrame 
        Contains the information about the matching annotation-image instances, where each row represents a patient's matched data
    '''
    #Create list for columns for initializing the "matching annotation to image" dataframe to be returned
    #Prefix "Ann" for information relating to or in the annotation file 
    #Prefix "Img" for information relating to or in the imaging file (CT, MRI, etc.)
    cols = ["AnnPatientID", 
            "ImgPatientID",
            "AnnStudyInstanceUID", #StudyInstanceUIDs should be the same between annotation and image if they have been matched properly
            "ImgStudyInstanceUID", 
            "AnnReferencedSeriesUID", #AnnReferencedSeriesUID should match ImgSeriesInstanceUID if they have been matched properly
            "ImgSeriesInstanceUID",  
            "ImgLocation", 
            "ImgSubSeries", 
            "ImgModality", 
            "AnnLocation", 
            "AnnSubSeries", 
            "AnnModality",
            "AnnSeriesInstanceUID" #Unique identifier for the annotation file
            ]
    
    matched_ann_image_df = pd.DataFrame(columns = cols)
    
    sr_df = idx_df[(idx_df["Modality"] == "SR")] #Specifically looks for structured reports as the annotation files.

    sr_ref_ser_UIDs = list()
    for ref_seriesUID in sr_df["ReferencedSeriesUID"].tolist(): 
        if ref_seriesUID in sr_ref_ser_UIDs: 
            #All SR's with a specific reference ID will be gotten on the first instance of it. Therefore skips the referenced imaging ID if it's already been searched for.   
            continue
        
        dupe_img_seriesID = False #Flag for a duplicate imaging series instance. Needed to check for multiple subseries. 

        sr_info = idx_df[(idx_df["Modality"] == "SR") & (idx_df["ReferencedSeriesUID"] == ref_seriesUID)].reset_index(drop = True) #Subset dataframe by the current imaging referenced by the annotation

        if sr_info.empty: 
            #Some of the SR's have no referenced imaging listed in the index. This is to handle this case and continue to the next SR's info.
            logger.info("A SR does not have a referenced image ID listed. Please consult the index.csv file.")
            continue

        if sr_info.shape[0] > 1: #Checks if multiple annotations were done on the same image
            logger.info("SR ReferencedSeriesUID for Patient ID: %s has one or more duplicates. Relevant data below:", sr_info["PatientID"].values[0])
            logger.info(sr_info)

        matching_image = idx_df[((idx_df["Modality"] == "CT") | (idx_df["Modality"] == "MR")) & (idx_df["SeriesInstanceUID"] == ref_seriesUID)].reset_index(drop = True) #Finds the matching imaging referenced by the annotation
        if matching_image.shape[0] > 1:
            #There is more than one mention of the referenced imaging in the index file. This usually means the imaging has multiple subseries.
            logger.debug("Imaging SeriesInstanceUID for Patient ID: %s has one or more duplicates. Relevant data below:", matching_image["PatientID"].values[0])
            logger.debug(matching_image)
            logger.debug(sr_info)
            dupe_img_seriesID = True

        elif matching_image.empty: 
            #Goes onto the next referenced imaging ID if no match for the current one was found in the index file. 
            logger.info("No matching imaging SeriesInstanceUID for Patient ID: %s with SR ReferencedSeriesUID: %s", sr_info["PatientID"].values[0], ref_seriesUID)
            continue

        if dupe_img_seriesID: 
            img_subseries = "N/A" #Set like this as an indicator further analysis is needed to find subseries. This is done in the match_ann_to_seg function.
        else: 
            img_subseries = matching_image["SubSeries"].values[0]

        for idx, row in sr_info.iterrows():  
            matched_info = [row["PatientID"],
                            matching_image["PatientID"].values[0], 
                            row["StudyInstanceUID"],
                            matching_image["StudyInstanceUID"].values[0],
                            row["ReferencedSeriesUID"],
                            matching_image["SeriesInstanceUID"].values[0],
                            matching_image["folder"].values[0], 
                            img_subseries, 
                            matching_image["Modality"].values[0],
                            row["folder"], 
                            row["SubSeries"], 
                            row["Modality"],
                            row["SeriesInstanceUID"]
                            ] 
            matched_df = pd.DataFrame([matched_info], columns = cols)
            matched_ann_image_df = pd.concat([matched_ann_image_df, matched_df])

        sr_ref_ser_UIDs.append(ref_seriesUID) #Adds current referenced imaging ID for the duplicate check at the start of the function. 

    matched_ann_image_df = matched_ann_image_df.reset_index(drop = True) #Makes sure all of the indices aren't just 0's, which can cause concat issues

    if matched_ann_image_df.empty: #Only entered if there are no matching images for any of the segmentations.
        raise ValueError("Annotation-image matching dataframe empty. No matches found.")

    return matched_ann_image_df

def match_img_to_seg(idx_df: pd.DataFrame, 
                     matched_ann_img_df: pd.DataFrame): 
    '''
    Of the images that have a SRs, find the matching image and SEG/RTSTRUCT pair. 
    
    Parameters
    ----------
    idx_df: pd.DataFrame 
        Contains the information found in the index.csv file generated by MedImageTools
    matched_ann_img_df: pd.DataFrame 
        Contains the relevant information necessary to find an image and SEG/RTSTRUCT pair from the SeriesInstanceUIDs

    Returns 
    ----------
    matched_img_seg_df: pd.DataFrame 
        Each imaging-segmentation pair of matched information is represented in each row    
    '''
    cols = ["SegPatientID",
            "ImgPatientID",  
            "SegStudyInstanceUID", 
            "ImgStudyInstanceUID",
            "SegReferencedSeriesUID",
            "ImgSeriesInstanceUID",
            "ImgLocation", 
            "ImgSubSeries",
            "SegModality",
            "SegLocation", 
            "SegSubSeries", 
            "SegSeriesInstanceUID",
           ]
    
    matched_img_seg_df = pd.DataFrame(columns = cols) #Initialize the final matched image-segmentation dataframe with appropriate columns.
     
    seg_df = idx_df[(idx_df["Modality"] == "RTSTRUCT") | (idx_df["Modality"] == "SEG")].reset_index(drop = True)  #Find any segmentation files that have RTSTRUCT or SEG structure (if more, add later)
 
    img_ser_UIDs = list()
    for idx_img, row_img in matched_ann_img_df.iterrows(): #Go through only the images that have annotation matches to see if they also have segmentations
        curr_img_ser_UID = row_img["ImgSeriesInstanceUID"]
        if curr_img_ser_UID in img_ser_UIDs:  #If already searched through this SeriesInstanceUID, skip. 
            continue

        matching_seg = seg_df[seg_df["ReferencedSeriesUID"] == curr_img_ser_UID].reset_index(drop = True) #Get all of the segmentations that reference the current imaging series ID 

        if matching_seg.shape[0] > 1: #Log if an image has more than one segmentation associated with it
            logger.info("Imaging SeriesInstanceUID: %s for Patient ID: %s has two or more segmentation ReferencedSeriesUID matches. Relevant data below: ", curr_img_ser_UID, row_img["ImgPatientID"])
            logger.info(matching_seg)
        elif matching_seg.empty: #If there are no matches, log and skip to next case.
            logger.info("Imaging SeriesInstanceUID: %s for Patient ID: %s does not have any segmentation matches", curr_img_ser_UID, row_img["ImgPatientID"])
            continue 

        for idx_seg, row_seg in matching_seg.iterrows(): #Record all segmentation data found to match the current image, each segmentation getting it's own row
            matched_info = [row_seg["PatientID"],
                            row_img["ImgPatientID"], 
                            row_seg["StudyInstanceUID"],
                            row_img["ImgStudyInstanceUID"],
                            row_seg["ReferencedSeriesUID"],
                            curr_img_ser_UID, 
                            row_img["ImgLocation"], 
                            row_img["ImgSubSeries"],
                            row_seg["Modality"],
                            row_seg["folder"], 
                            row_seg["SubSeries"], 
                            row_seg["SeriesInstanceUID"]
                            ]
            matched_df = pd.DataFrame([matched_info], columns = cols)
            matched_img_seg_df = pd.concat([matched_img_seg_df, matched_df])
        
        img_ser_UIDs.append(curr_img_ser_UID) #Add to list at start to make sure you don't search for the same image twice. 

    matched_img_seg_df = matched_img_seg_df.reset_index(drop = True) #Makes sure all of the indices aren't just 0's, which can cause concat issues
    
    if matched_img_seg_df.empty: #Only entered if the search ends up having no matching segmentations for any of the annotation-associated images. 
        raise ValueError("Image-segmentation matching dataframe empty. No matches found.")
    
    return matched_img_seg_df

def calc_intersection(pair_row: pd.Series): 
    '''
    Calculates the intersection point of the long and short axes. 

    Parameters
    ----------
    pair_row: pd.Series
        Contains at least the long and short axis coordinate information 
    
    Returns
    ----------
    interesection: list
        The point of intersection between the long and short axes. In the form [x_intersect, y_intersect]
    '''
    #Get long and short axis coordinates, defined by two points. Coordinates are listed as [x1, y1, x2, y2]
    long_ax_coords = pair_row["LongAxisCoords"]
    short_ax_coords = pair_row["ShortAxisCoords"] 
    
    #Create points from the long and short axis coordinate arrays 
    long_x1y1 = gm.Point(long_ax_coords[0], long_ax_coords[1])
    long_x2y2 = gm.Point(long_ax_coords[2], long_ax_coords[3])
    short_x1y1 = gm.Point(short_ax_coords[0], short_ax_coords[1])
    short_x2y2 = gm.Point(short_ax_coords[2], short_ax_coords[3])

    #Create the long and short axis lines defined by the points above
    long_axis = gm.Line(long_x1y1, long_x2y2)
    short_axis = gm.Line(short_x1y1, short_x2y2)

    #Calculate the intersection of the long and short axis measurements. 
    intersection_info = (long_axis.intersection(short_axis))[0].evalf()
    intersection = [intersection_info[0], intersection_info[1]]
    
    return intersection

def calc_midpoint(measure_row: pd.Series): 
    '''
    For measurement information which only has a long axis measurement. Calculates the midpoint of that measurement for 
    future annotation-segmentation confirmation. 

    Parameters
    ----------
    measure_row: pd.Series
        Contains at least the information for the long axis measurements. No short axis measurements should be listed
    
    Returns
    ----------
    midpoint: list
        The midpoint of the long axis measurement in the form [x_midpoint, y_midpoint]
    '''
    long_ax_coords = measure_row["LongAxisCoords"] #Get long axis measurement coordinates

    #Create points from the long and short axis coordinate arrays 
    long_x1y1 = gm.Point(long_ax_coords[0], long_ax_coords[1])
    long_x2y2 = gm.Point(long_ax_coords[2], long_ax_coords[3]) 

    #Create a segment, which will automatically have the midpoint attribute
    long_axis_segment = gm.Segment(long_x1y1, long_x2y2)
    midpoint = [long_axis_segment.midpoint[0], long_axis_segment.midpoint[1]]

    return midpoint

def get_point_of_interest(tum_info_df: pd.DataFrame): 
    '''
    Calculates the point of interest (POI) for tumour axis measurements. Used to confirm annotation-segmentation matching. 
    Warning: Edge case with concave polygonal tumours not necessarily covered by this check. 

    Parameters
    ----------
    tum_info_df: pd.DataFrame 
        Contains the long and short axis measurements, coordinates, and associated annotation information
    Returns
    ----------
    tum_info_and_POI_df: pd.DataFrame
        The same tum_info_df but with an added column named "AnnPointOfInterest" containing an array representing either the intersection point 
        of the long and short axis or the midpoint of the long axis [x, y] 
    '''
    axis_POIs = [] #Initialize array to hold the axis POIs. Will be in the form of [x, y]
    for idx, row in tum_info_df.iterrows(): #Goes through each of the annotation measurements (covers cases where multiple measurements are in the same SR)
        if row["ShortAxisCoords"] is None: 
            curr_POI = calc_midpoint(row)
        else: 
            curr_POI = calc_intersection(row)
        
        axis_POIs.append(curr_POI)
    
    #Add the intersections for each of the measurements into the tumour dataframe. Assumes that order of appended intersection points is the same as looping order. 
    tum_info_df["AnnPOI"] = axis_POIs 
    tum_info_and_intersect_df = tum_info_df

    return tum_info_and_intersect_df

def check_orthogonal(measure_coord_1: list, 
                     measure_coord_2: list, 
                     ortho_tol: float):
    '''
    Check to see if two measurements are orthogonal to each other. If they are not, they are not a long and short axis
    measurement pair.

    Parameters
    ----------
    measure_coord_1: list
        A list of coordinates that define the first line for comparison. In form [x1, y1, x2, y2]
    measure_coord_2: list 
        A list of coordinates that define the second line for comparison. In for [x1, y1, x2, y2]
    ortho_tol: float
        A tolerance value defining what the acceptible threshold is for the two lines to be considered orthogonal
    Returns
    ----------
    is_ortho: bool 
        True if the pair is orthogonal. False otherwise. 
    '''
    #Get the changes in x and y for both measurements. Used to check for infinite slope and for calculating slope
    delta_x_1 = measure_coord_1[2] - measure_coord_1[0]
    delta_x_2 = measure_coord_2[2] - measure_coord_2[0]

    delta_y_1 = measure_coord_1[3] - measure_coord_1[1]
    delta_y_2 = measure_coord_2[3] - measure_coord_2[1]

    #Check if both lines have infinite slope (are parallel and vertical, very unlikely to happen but handled nonetheless)
    if (delta_x_1 == 0 and delta_x_2 == 0): 
        is_ortho = False 

    #Check if one of the lines have infinite slope and if so, check if the other line is horizontal
    elif delta_x_1 == 0: 
        slope_2 = delta_y_2 / delta_x_2
        if abs(slope_2) <= ortho_tol: 
            is_ortho = True
        else: 
            is_ortho = False
    elif delta_x_2 == 0: 
        slope_1 = delta_y_1 / delta_x_1
        if abs(slope_1) <= ortho_tol: 
            is_ortho = True
        else: 
            is_ortho = False
    
    #Check if the product of the two slopes are within an interval centered at -1 (product == -1 --> truly orthogonal)
    else: 
        slope_1 = delta_y_1 / delta_x_1
        slope_2 = delta_y_2 / delta_x_2

        slope_product = slope_1 * slope_2

        if slope_product in range(-1 - ortho_tol, -1 + ortho_tol): 
            is_ortho = True 
        else: 
            is_ortho = False

    return is_ortho

def determine_long_short(measurements: list): 
    '''
    Based on a list of lists containing measurements and slice IDS, figure out which are on the same slice, if they are 
    considered orthogonal, and which measurements should be the long and short axis measurements. 

    Parameters
    ----------
    measurements: list 
        Containing RECIST measurements and information on which slice the measurments were taken on. Each list within
        this list is in the structure [measurement_type, measurement_unit, measurement_length, slice ID, line coordinates]
    
    Returns
    ----------
    long_axis_info: list
        Contains all information pertaining to the long axis measurement found. This will be in the order of
        [long_axis_measure_type, long_axis_measure_unit, long_axis_measurement, long_axis_SOPUID, long_axis_coordinates]
    short_axis_info: list 
        Contains all information pertaining to the short axis measurement found (if any). These values are null if no
        no short axis measurement was found. If found, they will be in the same order as the long axis information list.
    '''

    #Check length of list. If only one, there is no short axis measurement.
    num_of_measurements = len(measurements)

    long_axis_info = list()
    short_axis_info = list()

    if num_of_measurements == 1: 
        logger.debug("Only one measurement found in this SR.")
        #Returning here since the itertools combinations won't work with only one entry. 
        return long_axis_info, short_axis_info

    for measure_a, measure_b in itertools.combinations(measurements, 2):
        if measure_a[3] == measure_b[3]: #Check if on the same slice. Slice ID info found in 3rd index. 
            is_orthogonal = check_orthogonal(measure_coords_1 = measure_a[4], 
                                             measure_coord_2 = measure_b[4],
                                             ortho_tol = 0.001)
            if is_orthogonal: 
                logger.info("Orthogonal pair found for referenced slice: %s.", measure_a[3])

                #Check which measurement is longer to define long and short axis measurements
                if measure_a[2] > measure_b[2]: 
                    long_axis_info.append(measure_a)
                    short_axis_info.append(measure_b)
                else: 
                    long_axis_info.append(measure_b)
                    short_axis_info.append(measure_a)

    if len(long_axis_info) == 0: 
        logger.debug("No long and short axis pairs found.")
    
    return long_axis_info, short_axis_info

def organize_long_short_list(patient_ID: str, 
                             ann_seriesInstUID: str, 
                             ref_seriesUID: str, 
                             column_names: list,
                             long_axis_measurements: list,
                             short_axis_measurements: list):
    '''
    If long and short axis measurements were not explicitly defined, but pairs were found, organize them in the same format as the 
    curr_tum_info dataframe in preparation for concatenation. 

    Parameters
    ----------
    patient_ID: str
        The current patient's ID information 
    ann_seriesInstUID: str
        The current unique identifier for the annotation
    ref_seriesUID: str
        The imaging series ID that the annotation was drawn on
    column_names: list
        Contains all of the headers in the same order as the curr_tum_info dataframe
    long_axis_measurements: list 
        A list of lists containing the long axis measurement information (type, unit, length, slice ID, coordinates), where the 
        indices are aligned with the short axis indices' corresponding matches
    short_axis_measurements: list 
        A list of lists containing the short axis measurement information (type, unit, length, slice ID, coordinates), where
        the indices are aligned with the long axis indices' corresponding matches

    Returns
    ----------
    tum_info: pd.DataFrame
        Contains all measurements now labelled as long axis (no short axis measurements) in the same format as curr_tum_info in get_ann_measurements function
    '''
    tum_info = pd.DataFrame(columns = column_names)

    for idx in len(long_axis_measurements): 
        curr_info = [patient_ID, 
                     ann_seriesInstUID, 
                     ref_seriesUID, 
                     long_axis_measurements[idx][0], #Has long axis measurement type 
                     long_axis_measurements[idx][1], #Has long axis measurement unit
                     long_axis_measurements[idx][2], #Has long axis measurement length 
                     long_axis_measurements[idx][3], #Has long axis slice ID
                     long_axis_measurements[idx][4], #Has long axis measurement coordinates
                     short_axis_measurements[idx][0], #Has short axis measurement type 
                     short_axis_measurements[idx][1], #Has short axis measurement unit 
                     short_axis_measurements[idx][2], #Has short axis measurement length 
                     short_axis_measurements[idx][3], #Has short axis slice ID 
                     short_axis_measurements[idx][4] #Has short axis measurement coordinates
                    ]
        
        curr_info_df = pd.DataFrame([curr_info], columns = column_names) #Create dataframe with the current information organized in correct columns

        if tum_info.empty: 
            tum_info = curr_info_df #If there hasn't been any measurements added before, make the current info the dataframe instead of concatenating
        else: 
            tum_info = pd.concat([tum_info, curr_info_df])
    
    return tum_info

def organize_long_measures(patient_ID: str, 
                       ann_seriesInstUID: str, 
                       ref_seriesUID: str, 
                       column_names: list,
                       measurements: list): 
    '''
    If there are no long and short axis pairs found, this function will organize the data in the same format as the curr_tum_info dataframe in 
    preparation for concatenation. 

    Parameters
    ----------
    patient_ID: str
        The current patient's ID information 
    ann_seriesInstUID: str
        The current unique identifier for the annotation
    ref_seriesUID: str
        The imaging series ID that the annotation was drawn on
    column_names: list
        Contains all of the headers in the same order as the curr_tum_info dataframe
    measurements: list
        The list of measurements that were not listed as long or short axis to be organized

    Returns
    ----------
    tum_info: pd.DataFrame
        Contains all measurements now labelled as long axis (no short axis measurements) in the same format as curr_tum_info in get_ann_measurements function
    '''

    tum_info = pd.DataFrame(columns = column_names) #Initialize dataframe with appropriate columns

    for measurement in measurements: 
        curr_info = [patient_ID, 
                     ann_seriesInstUID, 
                     ref_seriesUID, 
                     measurement[0], #Has measurement type 
                     measurement[1], #Has measurement unit
                     measurement[2], #Has measurement length 
                     measurement[3], #Has slice ID
                     measurement[4], #Has measurement coordinates
                     None, 
                     None, 
                     None, 
                     None, 
                     None]
        
        curr_info_df = pd.DataFrame([curr_info], columns = column_names) #Create dataframe with the current information organized in correct columns

        if tum_info.empty: 
            tum_info = curr_info_df #If there hasn't been any measurements added before, make the current info the dataframe instead of concatenating
        else: 
            tum_info = pd.concat([tum_info, curr_info_df])
    
    return tum_info
    
def get_ann_measurements(ann_dicom_file_path: Path): 
    '''
    Scrapes the raw annotation DICOM file for information relating to long axis measurements. Logs all possible measurements. 
    Assumes all relevant data in the SR follows the same structure and depth and that all measurements correspond to relevant tumours.

    Parameters
    ----------
    ann_dicom_file_path: Path
        Path to SR file

    Returns 
    ----------
    all_tum_info_df: pd.DataFrame
        Contains information related to file and the long and short axis measurements
    '''
    #Columns used to describe the information obtained and outputted in the tumour info dataframe. Each row represents an annotation found in the SR file.
    #Intersection column header not mentioned as this is calculated and added after all information found in the SR file has been compiled and entered into the tumour info dataframe. 
    cols = ["AnnPatientID",
            "AnnSeriesInstanceUID", #Unique file identifier for annotation file
            "AnnReferencedSeriesUID", #The image ID that the annotation file references
            "LongAxisMeasureType", 
            "LongAxisUnit", 
            "LongAxisMeasurement", 
            "LongAxisRefSOPUID", #The slice that the long axis was drawn on
            "LongAxisCoords",  
            "ShortAxisMeasureType", 
            "ShortAxisUnit", 
            "ShortAxisMeasurement", 
            "ShortAxisRefSOPUID", #The slice the short axis was drawn on. This should be the same as the long axis slice for each row
            "ShortAxisCoords"]
    
    tum_info_df = pd.DataFrame(columns = cols) #Initialize tumour info datarame 
    try:
        dicom_data = pydicom.dcmread(ann_dicom_file_path) #Read in the DICOM data from the SR file
    except FileNotFoundError:
        logger.info("File: %s is was listed in index file but is not in the segmentation subset available on lab server. Skipping.", ann_dicom_file_path)
        return pd.DataFrame()
    
    #Access and gather information relevant to the matching process. Logs the process in the corresponding logger file. 
    #For more information on how this DICOM data is structured and why certain indices are accessed, please refer to the devnotes_kaitlyn.md file
    ann_seriesInstUID = dicom_data.SeriesInstanceUID
    ann_patientID = dicom_data.PatientID
    parent_cont_seq = dicom_data.ContentSequence
    ann_refSeriesInstUID = dicom_data.CurrentRequestedProcedureEvidenceSequence[0]["ReferencedSeriesSequence"][0]["SeriesInstanceUID"].value
    
    logger.info("Measurements being obtained for file: %s", ann_dicom_file_path)

    length_measurements = list()
    cont_sequence1_len = len(parent_cont_seq[4]["ContentSequence"].value)
    for cont_seq in range(cont_sequence1_len):
        cont_sequence2_len = len(parent_cont_seq[4]["ContentSequence"][cont_seq]["ContentSequence"].value)
        for cont_seq2 in range(cont_sequence2_len): #This should be redone into a more systematic search for a "long axis" or "short axis" value later.
            conc_name_code_seq = parent_cont_seq[4]["ContentSequence"][cont_seq]["ContentSequence"][cont_seq2]["ConceptNameCodeSequence"][0]["CodeMeaning"].value
            if conc_name_code_seq == "Long Axis": 
                measure_type_long = parent_cont_seq[4]["ContentSequence"][cont_seq]["ContentSequence"][cont_seq2]["ConceptNameCodeSequence"][0]["CodeMeaning"].value
                measure_unit_long = parent_cont_seq[4]["ContentSequence"][cont_seq]["ContentSequence"][cont_seq2]["MeasuredValueSequence"][0]["MeasurementUnitsCodeSequence"][0]["CodeValue"].value
                measurement_long = parent_cont_seq[4]["ContentSequence"][cont_seq]["ContentSequence"][cont_seq2]["MeasuredValueSequence"][0]["NumericValue"].value
                ref_SOPUID_long = parent_cont_seq[4]["ContentSequence"][cont_seq]["ContentSequence"][cont_seq2]["ContentSequence"][0]["ContentSequence"][0]["ReferencedSOPSequence"][0]["ReferencedSOPInstanceUID"].value
                long_axis_points = []
                for point_long in range(4): #For (x1, y1) (x2, y2) coordinates to make the long axis
                    #Rounding because of conversion errors causing duplicate annotations not to be detected. 
                    point = round(parent_cont_seq[4]["ContentSequence"][cont_seq]["ContentSequence"][cont_seq2]["ContentSequence"][0]["GraphicData"][point_long], 2)
                    long_axis_points.append(point)

                logger.info("Long axis measurement of type %s and units %s has been obtained.", measure_type_long, measure_unit_long)
                logger.info("Long axis easurement value: %s", measurement_long)
                logger.info("Long axis corresponding ReferencedSOPUID: %s", ref_SOPUID_long)
                logger.info("Long axis coordinates: %s", long_axis_points)
            elif conc_name_code_seq == "Short Axis":
                measure_type_short = parent_cont_seq[4]["ContentSequence"][cont_seq]["ContentSequence"][cont_seq2]["ConceptNameCodeSequence"][0]["CodeMeaning"].value
                measure_unit_short = parent_cont_seq[4]["ContentSequence"][cont_seq]["ContentSequence"][cont_seq2]["MeasuredValueSequence"][0]["MeasurementUnitsCodeSequence"][0]["CodeValue"].value
                measurement_short = parent_cont_seq[4]["ContentSequence"][cont_seq]["ContentSequence"][cont_seq2]["MeasuredValueSequence"][0]["NumericValue"].value
                ref_SOPUID_short = parent_cont_seq[4]["ContentSequence"][cont_seq]["ContentSequence"][cont_seq2]["ContentSequence"][0]["ContentSequence"][0]["ReferencedSOPSequence"][0]["ReferencedSOPInstanceUID"].value
                short_axis_points = []
                for point_short in range(4): #Same as above but for the short axis instead
                    #Rounding because of conversion errors causing duplicate annotations not to be detected. 
                    point = round(parent_cont_seq[4]["ContentSequence"][cont_seq]["ContentSequence"][cont_seq2]["ContentSequence"][0]["GraphicData"][point_short], 2)
                    short_axis_points.append(point)
                
                logger.info("Short axis measurement of type %s and units %s has been obtained.", measure_type_short, measure_unit_short)
                logger.info("Short axis measurement value: %s", measurement_short)
                logger.info("Short axis corresponding ReferencedSOPUID: %s", ref_SOPUID_short)
                logger.info("Short axis coordinates: %s ", short_axis_points)

            elif conc_name_code_seq == "Length": #For measurements that are not explicitly defined as an axis measurement. Present in OCTANE data.
                measure_type = parent_cont_seq[4]["ContentSequence"][cont_seq]["ContentSequence"][cont_seq2]["ConceptNameCodeSequence"][0]["CodeMeaning"].value
                measure_unit = parent_cont_seq[4]["ContentSequence"][cont_seq]["ContentSequence"][cont_seq2]["MeasuredValueSequence"][0]["MeasurementUnitsCodeSequence"][0]["CodeValue"].value
                measurement = parent_cont_seq[4]["ContentSequence"][cont_seq]["ContentSequence"][cont_seq2]["MeasuredValueSequence"][0]["NumericValue"].value
                ref_SOPUID = parent_cont_seq[4]["ContentSequence"][cont_seq]["ContentSequence"][cont_seq2]["ContentSequence"][0]["ContentSequence"][0]["ReferencedSOPSequence"][0]["ReferencedSOPInstanceUID"].value
                axis_points = []
                for pnt in range(4): #Same as above but for ambiguous measurements
                    #Rounding because of conversion errors causing duplicate annotations not to be detected. 
                    point = round(parent_cont_seq[4]["ContentSequence"][cont_seq]["ContentSequence"][cont_seq2]["ContentSequence"][0]["GraphicData"][pnt], 2)
                    axis_points.append(point)
                
                length_info = [measure_type, measure_unit, measurement, ref_SOPUID, axis_points]
                length_measurements.append(length_info)

        #Check if any measurements were found
        try:
            #Check to make sure long and short axis measurements were taken on same slice. 
            if ref_SOPUID_long != ref_SOPUID_short: 
                logger.debug("Long and short axis measurements for SeriesInstanceUID %s not taken on the same slice")
                logger.debug("Long axis RefSOPUID: %s", ref_SOPUID_long)
                logger.debug("Short axis RefSOPUID: %s", ref_SOPUID_short)

            #Create one row dataframe of current annotation information with the same structure as the overall tumour info to prep it for concatenation. 
            curr_tum_info = [ann_patientID,
                            ann_seriesInstUID, 
                            ann_refSeriesInstUID,
                            measure_type_long, 
                            measure_unit_long,
                            measurement_long, 
                            ref_SOPUID_long, 
                            long_axis_points,
                            measure_type_short,
                            measure_unit_short,
                            measurement_short, 
                            ref_SOPUID_short, 
                            short_axis_points]
            
            curr_tum_df = pd.DataFrame([curr_tum_info], columns = cols)
        
            #Checks if anything has been added to the initial dataframe yet and then concatenates current information with the previously gathered information if applicable. 
            if tum_info_df.empty: 
                tum_info_df = curr_tum_df
            else:
                tum_info_df = pd.concat([tum_info_df, curr_tum_df])

        except NameError: 
            logger.debug("No long and short axis measurements defined yet. Continuing search for measurements for SeriesInstanceUID: %s", ann_seriesInstUID)
            continue


    #If you've gotten all measurements, check if any need further definition as long or short axis measurements
    if (cont_seq == cont_sequence1_len - 1) and (cont_seq2 == cont_sequence2_len - 1):
        #Check if there were any measurements labelled "Length"
        if len(length_measurements) > 0: 
            long_axis_list, short_axis_list = determine_long_short(length_measurements)
            #If axis pair was found, assign appropriate values to the varaibles of interest
            if len(long_axis_list) > 0:
                curr_tum_df = organize_long_short_list(patient_ID = ann_patientID, 
                                                       ann_seriesInstUID = ann_seriesInstUID,
                                                       ref_seriesUID = ann_refSeriesInstUID, 
                                                       column_names = cols, 
                                                       long_axis_measurements = long_axis_list, 
                                                       short_axis_measurements = short_axis_list
                                                       )
            else: 
                curr_tum_df = organize_long_measures(patient_ID = ann_patientID, 
                                                     ann_seriesInstUID = ann_seriesInstUID, 
                                                     ref_seriesUID = ann_refSeriesInstUID, 
                                                     column_names = cols, 
                                                     measurements = length_measurements)

            if tum_info_df.empty: 
                tum_info_df = curr_tum_df
            else:
                tum_info_df = pd.concat([tum_info_df, curr_tum_df])

    #Get the intersection point of the long and short axes. To be used to confirm annotation-segmentation match later. 
    all_tum_info_df = get_point_of_interest(tum_info_df)

    return all_tum_info_df

def get_rtstruct_SOPUIDs(rtstruct_dicom_path: Path):
    '''
    Gathers all referencedSOPInstanceUIDs (slices) for the given segmentation. 
    Assumes only one DICOM file per folder and one segmentation per DICOM file. 

    Parameters
    ----------
    rtstruct_dicom_path: Path   
        Path to RTSTRUCT file

    Returns
    rtstruct_SOPUIDs: list 
        Contains all of the mentioned slice IDs in the given RTSTRUCT file. 
    '''

    #Read in the current RTSTRUCT DICOM data. 
    #For more information on why this function is necessary and the indices and sequences chosen, please refer to the devnotes_kaitlyn.md file. 
    dicom_data = pydicom.dcmread(rtstruct_dicom_path)
    
    #Navigate to the segmentation slice ID information. 
    parent_sequence = dicom_data.ReferencedFrameOfReferenceSequence
    seg_seq = parent_sequence[0]["RTReferencedStudySequence"][0]["RTReferencedSeriesSequence"][0]["ContourImageSequence"]

    #Go through all of the items in the contour image sequence and find and denote the slice IDs found. 
    rtstruct_SOPUIDs = list()
    for element in range(len(seg_seq.value)): 
        if "ReferencedSOPInstanceUID" in seg_seq[element]: 
            curr_SOPUID = seg_seq[element]["ReferencedSOPInstanceUID"].value
            rtstruct_SOPUIDs.append(curr_SOPUID)

    return rtstruct_SOPUIDs

def compare_niftis(nifti_ser = pd.Series): 
    '''
    Compares segmentation nifti files to see if they contain the same information. 

    Parameters
    ----------
    nifti_ser: pd.Series
        Contains the nifti files to compare. 
    
    Returns
    ----------
    same_segments: bool 
        Flags whether all the nifti files tested were the same. 
    '''
    possible_segs = nifti_ser.to_list()
    for nifti_a, nifti_b in itertools.combinations(possible_segs, 2): #Iterate over all unique combinations of nifti files 
        seg_nifti_a = sitk.ReadImage(nifti_a) 
        seg_nifti_b = sitk.ReadImage(nifti_b)

        #Convert segmentations to arrays for comparison 
        arr_nifti_a = sitk.GetArrayFromImage(seg_nifti_a) 
        arr_nifti_b = sitk.GetArrayFromImage(seg_nifti_b)

        same_segments = np.array_equal(arr_nifti_a, arr_nifti_b)
        if not same_segments: 
            logger.debug("Nifti files %s and %s are mapped to the same SeriesInstanceUID but are not the same. Please investigate.", str(nifti_a), str(nifti_b))
            break
    
    return same_segments

def check_nifti_exists(nifti_series: pd.Series): 
    '''
    For file paths in a series, check if they exist and can be found. 

    Parameters
    ----------
    nifti_series: pd.Series
        Contains all file paths in Path form that are going to be checked
    
    Returns
    ----------
    exist_niftis: pd.Series
        Contains only the paths that are accessible 
    '''
    exist_niftis = pd.Series()
    for path in nifti_series: 
        if path.is_file(): 
            exist_niftis = pd.concat([exist_niftis, pd.Series(data = path)])
    
    return exist_niftis

def get_nifti_locs(nifti_idx_path: Path, 
                   img_seg_info: pd.DataFrame): 
    '''
    Gets the file locations of the nifti files for CT image and associated segmentation. 
    
    Parameters
    ----------
    nifti_idx_path: Path
        Path to index file created by med-imagetools for the nifti versions of the CT and segmentation files  
    img_seg_info: pd.DataFrame 
        A one-row dataframe containing the current image and segmentation information

    Returns 
    ----------
    img_nifti_path: Path 
        Path to the CT imaging nifti file 
    seg_nifti_path: pd.Series 
        Path to the associated segmentation nifti file 
    '''
    no_nifti = False #Flag set for testing if the corresponding DICOM files got converted to nifti successfully. 
    nifti_path = Path("/".join(str(nifti_idx_path).split("/")[:-1])) #nifti files in same folder as nifti index file, so want to get just the path to that folder.
    nifti_idx_df = pd.read_csv(nifti_idx_path) #Read in nifti index info to get the corresponding nifti filenames and relative paths

    #Get the unique identifiers for the image and the segmentation files. 
    img_instUID = img_seg_info["ImgSeriesInstanceUID"].values[0]
    seg_instUID = img_seg_info["SegSeriesInstanceUID"].values[0]

    #Using the image and segmentation IDs, find their corresponding nifti conversion filepaths from the index file. 
    img_nifti = nifti_idx_df[nifti_idx_df["SeriesInstanceUID"] == img_instUID]["filepath"]
    seg_nifti = nifti_idx_df[nifti_idx_df["SeriesInstanceUID"] == seg_instUID]["filepath"]

    #Check if the matching was successful. If there is either a missing imaging or segmentation nifti conversion, raise flag.
    if img_nifti.empty: 
        logger.info("Imaging SeriesInstanceUID: %s does not have a matching nifti file.", img_instUID)
        no_nifti = True
    elif seg_nifti.empty: 
        logger.info("Segmentation SeriesInstanceUID: %s does not have a matching nifti file.", seg_instUID)
        no_nifti = True
    
    #If there isn't a match, return empty series for both. 
    #Using the empty series so I can do an equality comparison of path variables in the annotation-segmentation confirmation and return a no match if both variables are blank. 
    if no_nifti: 
        return pd.Series(), pd.Series()
    
    img_niftis = nifti_path / img_nifti
    seg_niftis = nifti_path / seg_nifti

    #Test to see if the nifti files mentioned are accessible 
    img_niftis = check_nifti_exists(img_niftis)
    seg_niftis = check_nifti_exists(seg_niftis)

    #Check for multiple images mapped to the same SeriesInstanceUID 
    if img_niftis.size > 1: 
        logger.debug("Multiple images mapped to the same series instance UIDs. Information below:")
        logger.debug(img_niftis)

        are_dupes = compare_niftis(nifti_ser = img_niftis)
        if are_dupes:
            logger.debug("Image niftis listed below are the same: ")
            logger.debug(img_niftis)
            img_niftis = pd.Series(data = img_niftis.iloc[0])

    #Check for multiple segmentation niftis mapped to the same SeriesInstanceUID 
    if seg_niftis.size > 1: 
        #Want to see if the files listed are just duplicates or if two segmentations got mapped to the same SeriesInstanceUID 
        are_dupes = compare_niftis(nifti_ser = seg_niftis)
        if are_dupes: 
            # seg_nifti_path = seg_niftis.iloc[0] #If all the files are the same, just pick the first one
            logger.debug("Segmentations listed below are the same: ")
            logger.debug(seg_niftis)
            seg_niftis = pd.Series(data = seg_niftis.iloc[0])
    
    return img_niftis, seg_niftis

def get_slice_num(inst_slice: str, 
                  num_of_slices: int): 
    '''
    Gets the slice number of based on an instances value from a given referencedSOPUID and then matches it to the order of the nifti slices.

    Parameters
    ----------
    inst_slice: str
        Reference of the dicom slice file
    num_of_slices: int 
        Number of slices that are in the whole image
    Returns 
    ----------
    slice_num 
        The slice number aligned with the nifti slices
    '''

    subseries_slice = inst_slice.split(".")[0] #Takes the name of the DICOM instance and removes the ".dcm" at the end
    dicom_slice = int(subseries_slice.split("-")[-1]) #Gets the slice number from the name of the DICOM instance. See devnotes_kaitlyn.md for more.

    slice_num = num_of_slices - dicom_slice + 1 #See devnotes_kaitlyn.md for breakdown of this calculation. 
    
    return slice_num 

def plot_img_seg_ann(tum_info: pd.Series,
                     img_slice: np.array,
                     seg_slice: np.array, 
                     save_path: Path): 
    '''
    Plots the annotation measured axes and the intersection point on the corresponding segmentation overlaying the image slice. 

    Parameters
    ----------
    tum_info: pd.Series
        Contains all information relevant to the current annotation 
    img_slice: np.array
        Imaging slice information 
    seg_slice: np.array 
        Segmentation slice information 
    save_path: Path 
        Where to save the plot once finished
    '''
    
    plt.imshow(img_slice, cmap="Greys_r") #Plot imaging with a grayscale adjustment. 
    plt.imshow(seg_slice, alpha = 0.7, cmap ="Accent") #Overlay the a translucent segmentation mask over the image to denote the tumour. 
    plt.plot([tum_info["LongAxisCoords"][0], tum_info["LongAxisCoords"][2]], 
               [tum_info["LongAxisCoords"][1], tum_info["LongAxisCoords"][3]], 
               'ro-', markersize = 2, linewidth = 1) #Plots the long axis line in red.
    
    if tum_info["ShortAxisCoords"] is not None: #If there was a short axis match to the long axis measurement, plot it
        plt.plot([tum_info["ShortAxisCoords"][0], tum_info["ShortAxisCoords"][2]], 
                [tum_info["ShortAxisCoords"][1], tum_info["ShortAxisCoords"][3]], 
                'bo-', markersize = 2, linewidth = 1) #Plots the short axis line in blue.
        
    plt.plot(tum_info["AnnPOI"][0], tum_info["AnnPOI"][1], 
             'yo', markersize = 2) #Plots the intersection of the short and long axis by a yellow dot. 
    plt.text(2, -5, "RefSOPUID: " + tum_info["LongAxisRefSOPUID"], fontsize=6) #Put the slice ID so it can differentiate from different annotations

    patient_ann = 0
    save_name = tum_info["AnnPatientID"] + "_" + str(patient_ann) + ".png" #Create plot save name
    out_path = save_path / save_name 
    while out_path.exists(): #If a patient has multiple annotations, it needs to differentiate between them in the file name or else the plots will override themselves. 
        patient_ann +=1
        save_name = tum_info["AnnPatientID"] + "_" + str(patient_ann) + ".png"
        out_path = save_path / save_name 

    plt.savefig(out_path)

    plt.close()

def confirm_ann_seg_match(tum_info_df: pd.DataFrame, 
                          img_nifti_path: Path,
                          seg_nifti_path: Path,
                          dicom_data_dict: dict,
                          image_subseries: str,
                          overlay_out_path: Path): 
    '''
    Checks whether an intersection point is within the segmentation of a specific file. Overlays image, annotation, and segmentation for 
    visual confirmation as well. 

    Parameters
    ----------
    tum_info_df: pd.DataFrame
        Contains the long and short axis and intersection information
    img_nifti_path: Path 
        Path to the associated imaging nifti file 
    seg_nifti_path: Path
        Path to the associated segmentation nifti file
    dicom_data_dict: dict
        Contains all information related to the crawl_db.json file
    image_subseries: str
        CT subseries number that will help access the correct DICOM information
    overlay_out_path: Path 
        Path to where the overlayed image will be saved

    Returns
    ---------
    is_in_seg: bool 
        Returns 0 if intersection is not in the segmentation and 1 if it is
    '''    
    #Read in the image and segmentation nifti files
    img_nifti = sitk.ReadImage(img_nifti_path) 
    seg_nifti = sitk.ReadImage(seg_nifti_path)

    #Turn image and segmentation into arrays
    img_arr = sitk.GetArrayFromImage(img_nifti)
    seg_arr = sitk.GetArrayFromImage(seg_nifti)
    np_seg_arr = np.ma.masked_where(seg_arr == 0, seg_arr) #Preps the segmentation array for visualization, but does not hold the correct information for actual confirmation. 

    #Get the number of slices in the image and segmentation. 
    img_slice_num = img_arr.shape[0] 
    np_seg_slice_num = np_seg_arr.shape[0]

    if img_slice_num != np_seg_slice_num: 
        #Only entered if the imaging and segmentation do not have a matching number of slices. This shouldn't happen if the 
        #image and segmentation have been properly matched. For debugging purposes only. Return a no match if this happens.
        logger.debug("Image and segmentation have different number of slices. See below for relevant information: ")
        logger.debug("Nifti image path: %s", img_nifti_path)
        logger.debug("Nifti segmentation path: %s", seg_nifti_path)

        return 0 

    #This should really only be one row with the current setup, but is set up this way in case there are multiple annotations with the same ID
    #Iterate through the annotations, find the corresponding image and segmentation slice, and determine if the intersection point is within the segmentation mask. 
    #If so, plot the match and save for further visualization. 
    for idx, row in tum_info_df.iterrows(): 
        #Find the corresponding
        img_seriesInstUID = row["AnnReferencedSeriesUID"] 
        number_of_slices = img_slice_num
        img_slice_dicom = dicom_data_dict[img_seriesInstUID][image_subseries]["instances"][row["LongAxisRefSOPUID"]] #Get the slice instance name based on the referenced slice ID.
        
        slice_num = get_slice_num(img_slice_dicom, number_of_slices)

        img_slice = img_arr[slice_num]
        seg_slice = seg_arr[slice_num]
        np_seg_slice = np_seg_arr[slice_num]

        is_in_seg = seg_slice[round(row["AnnPOI"][1])][round(row["AnnPOI"][0])]

        if is_in_seg: 
            plot_img_seg_ann(row, img_slice, np_seg_slice, overlay_out_path)

    return is_in_seg

def find_correct_seg(seg_folder: Path, 
                     seg_seriesInstUID: str): 
    '''
    Given a folder with multiple segmentations, go through all files and check the segmentation series ID and finds the file that matches the currently desired segmentation. 

    Parameters 
    ----------
    seg_folder: Path
        Folder containing the segmentations DICOM files to be tested. 
    seg_seriesInstUID: str
        The segmentation series that is trying to be matched. 

    Returns
    ----------
    correct_seg_path: Path, 
        The path to the segmentation DICOM file that was found to match the series ID
    '''

    for f in seg_folder.iterdir(): 
        curr_filepath = seg_folder / f.name
        
        curr_dicom_info = pydicom.dcmread(curr_filepath) #Read in the current file to access the dicom information. 
        curr_seriesInstUID = curr_dicom_info.SeriesInstanceUID #Get the current file's Series Instance UID 

        if curr_seriesInstUID == seg_seriesInstUID: #If this series instance UID is the same as the one that is trying to be matched, store the filepath 
            correct_seg_path = curr_filepath
            break

    #Check to see if there was ever a match and if there wasn't, log and return 0
    try: 
        correct_seg_path 
    except NameError: 
        logger.error("Segmentation DICOM listed as existing in the folder %s, but no match found.", str(seg_folder))
        logger.error("Segmentation SeriesInstanceUID being searched for: %s", seg_seriesInstUID)
        return ""
    
    return correct_seg_path

def match_ann_to_seg(match_ann_img_df: pd.DataFrame, 
                     match_img_seg_df: pd.DataFrame, 
                     dicom_info_dict: dict, 
                     nifti_idx_path: Path,
                     ann_seg_dicom_path: Path,
                     img_out_path: Path):
    '''
    Using the information from the previous two functions above, find which segmentation the annotation belongs to
    via checking if the annotation slice is referenced in the segmentation list of slices and confirming whether the long and short axis 
    intersection is within the segmentation given. Also outputs visualization of the image, segmentation, and intersection. 

    Parameters 
    ----------
    match_ann_img_df: pd.DataFrame
        Contains the information about the matching annotation-image instances, where each row represents a patient's matched data
    match_img_seg_df: pd.DataFrame
        Each imaging-segmentation pair of matched information is represented in each row
    dicom_info_dict: dict 
        Contains the DICOM information found in the med-imagetools generated crawl_db.json file. 
    nifti_idx_path: Path
        Path to index file created by med-imagetools for the nifti versions of the CT and segmentation files
    ann_seg_dicom_path: Path 
        Path to folder holding all raw SEG/RTSTRUCT and SR DICOM data
    img_out_path: Path
        Path to folder where the overlay image-segmentation-annotation images will go

    Returns
    ----------
    match_info_summary: pd.DataFrame 
        Contains the SEG or RTSTRUCT, SR, and imaging paired information. 
    no_match_info_summary: pd.DataFrame
        Contains the information for annotations that do not have segmentation matches. Segmentation info left blank. 
    '''
    cols = ["PatientID", 
            "StudyInstanceUID", 
            "ImgSeriesInstanceUID", 
            "AnnReferencedSeriesUID", 
            "SegReferencedSeriesUID", 
            "AnnSeriesInstanceUID", 
            "SegSeriesInstanceUIDs", 
            "AnnReferencedSOPUID", 
            "AnnLongAxisLength", 
            "AnnLongAxisMeasureType", 
            "AnnLongAxisMeasureUnit",
            "AnnLongAxisCoordinates", 
            "AnnShortAxisLength", 
            "AnnShortAxisMeasureType", 
            "AnnShortAxisMeasureUnit",
            "AnnShortAxisCoordinates", 
            "AnnPOI", 
            "ImgModality", 
            "AnnModality", 
            "SegModality", 
            "ImgSubSeries", 
            "ImgLocation", 
            "AnnLocation",
            "AnnFilename", 
            "SegLocation", 
            "ImgNIFTILocation", 
            "SegNIFTILocation"       
           ]
    
    match_info_summary = pd.DataFrame(columns = cols) 
    no_match_info_summary = pd.DataFrame(columns = cols)

    for ann_seriesInstUID in match_ann_img_df["AnnSeriesInstanceUID"]:
        img_ann_info = match_ann_img_df[match_ann_img_df["AnnSeriesInstanceUID"] == ann_seriesInstUID]
        ann_series_info = dicom_info_dict[ann_seriesInstUID]
        ann_dicom_info = ann_series_info["1"] #Assumes that all SRs have SubSeries "1" and only "1"

        ann_refSOPUIDs = ann_dicom_info["ReferencedSOPUIDs"]
        if len(ann_refSOPUIDs) > 1: 
            logger.debug("More than one slice referenced in annotation SeriesInstanceUID: %s", ann_seriesInstUID)
            logger.debug("Slices listed: ") 
            logger.debug(ann_refSOPUIDs)

        #Get RECIST measurement and check though all measurements if multiple
        inst = list(ann_dicom_info["instances"])
        filename = ann_dicom_info["instances"][inst[0]]
        logger.info("Corresponding annotation file for below measurements: %s", filename) #Assumes only one instance for each SR
        
        ann_file_path = ann_seg_dicom_path / img_ann_info["AnnLocation"].iloc[0] / filename
        tum_measurements = get_ann_measurements(ann_file_path)
        if tum_measurements.empty:
            continue #If entering this check, this means that the annotation DICOM file is currently unavailable
        
        ann_refSeriesUID = ann_dicom_info["ReferencedSeriesUID"]
        
        for refSOPUID in ann_refSOPUIDs: 
            curr_measurements = tum_measurements[tum_measurements["LongAxisRefSOPUID"] == refSOPUID]
            if curr_measurements.shape[0] > 1: 
                logger.debug("Multiple long axis measurements on the same slice")

            #Handling duplicate imaging SeriesInstanceUIDs (for ones with multiple SubSeries) 
            if img_ann_info["ImgSubSeries"].values[0] == "N/A": 
                logger.info("Finding correct imaging subseries.")
                img_ser_instUID = img_ann_info["ImgSeriesInstanceUID"].values[0]
                image_series_info = dicom_info_dict[img_ser_instUID]
                for subseries in image_series_info: 
                    image_dicom_info = image_series_info[str(subseries)]
                    img_inst = list(image_dicom_info['instances'])
                    if refSOPUID in img_inst: 
                        img_subseries = str(subseries)
            else: 
                img_subseries = str(img_ann_info["ImgSubSeries"].values[0])

            match_seg_tests = match_img_seg_df[match_img_seg_df["SegReferencedSeriesUID"] == ann_refSeriesUID] 

            potential_seg_matches = list()

            for seg_seriesInstUID in match_seg_tests["SegSeriesInstanceUID"]: 
                curr_info = match_seg_tests[match_seg_tests["SegSeriesInstanceUID"] == seg_seriesInstUID]
                seg_series_info = dicom_info_dict[seg_seriesInstUID]
                seg_dicom_info = seg_series_info["1"] #Assumes the same as SRs subseries

                if curr_info["SegModality"].values[0] == "SEG": 
                    seg_refSOPUIDs = seg_dicom_info["ReferencedSOPUIDs"]
                    if len(list(seg_dicom_info["instances"])) > 1: 
                        logger.debug("More than one segmentation found in the segmentation file for Patient ID: %s. Please double check this. Relevant data below:", seg_dicom_info["PatientID"])
                        logger.debug(seg_refSOPUIDs)
                        continue
                    
                elif curr_info["SegModality"].values[0] == "RTSTRUCT": 
                    seg_partial_path = seg_dicom_info["folder"]
                    #Check for multiple files within the folder
                    seg_dicom_folder = ann_seg_dicom_path / seg_partial_path
                    file_num = len([f for f in seg_dicom_folder.iterdir() if f.is_file()]) #Gets number of files in the folder to see if additional searching for the correct segmentation is necessary.
                    if file_num > 1: 
                        #Check each one for the correct segmentation series instance UID. 
                        seg_dicom_file = find_correct_seg(seg_folder = seg_dicom_folder, seg_seriesInstUID = seg_seriesInstUID)
                    
                        if seg_dicom_file == "": #No file match found for the current segmentation (not where it's supposed to be or doesn't exist). Continue to the next potential match.
                            continue

                    else: 
                        seg_filename = [f for f in seg_dicom_folder.iterdir()][0] #Get the only filename in that folder
                        seg_dicom_file = seg_dicom_folder / seg_filename
                    
                    seg_refSOPUIDs = get_rtstruct_SOPUIDs(seg_dicom_file)

                else: 
                    logger.error("Segmentation modality %s is currently not supported. Skipping segmentation", curr_info["SegModality"])

                if refSOPUID in seg_refSOPUIDs: 
                    potential_seg_matches.append(seg_dicom_info["SeriesInstanceUID"])

            if len(potential_seg_matches) > 1: 
                logger.debug("Annotation-segmentation matching indeterminant for annotation SeriesInstanceUID: %s. Annotation within multiple segmentation slices.", ann_refSeriesUID)
                logger.debug("Potential segmentation matches for %s: %s", ann_refSeriesUID, potential_seg_matches)
            elif len(potential_seg_matches) < 1: 
                logger.debug("No segmentation match found for annotation SeriesInstanceUID: %s with ReferencedSOPUID: %s", ann_seriesInstUID, refSOPUID)
                no_matched_info = [ann_dicom_info["PatientID"], 
                            ann_dicom_info["StudyInstanceUID"], 
                            img_ann_info["ImgSeriesInstanceUID"].values[0], 
                            ann_refSeriesUID,  
                            seg_dicom_info["ReferencedSeriesUID"], #Assumes that all potential seg matches have the same ref image
                            ann_dicom_info["SeriesInstanceUID"], 
                            potential_seg_matches, 
                            refSOPUID, 
                            curr_measurements["LongAxisMeasurement"].values[0],
                            curr_measurements["LongAxisMeasureType"].values[0], 
                            curr_measurements["LongAxisUnit"].values[0],
                            curr_measurements["LongAxisCoords"].values[0],
                            curr_measurements["ShortAxisMeasurement"].values[0], 
                            curr_measurements["ShortAxisMeasureType"].values[0], 
                            curr_measurements["ShortAxisUnit"].values[0],
                            curr_measurements["ShortAxisCoords"].values[0],
                            curr_measurements["AnnPOI"].values[0],
                            img_ann_info["ImgModality"].values[0], 
                            ann_dicom_info["Modality"], 
                            seg_dicom_info["Modality"],
                            img_subseries, 
                            img_ann_info["ImgLocation"].values[0], 
                            img_ann_info["AnnLocation"].values[0],
                            filename,
                            None,
                            None, 
                            None]
                
                no_match_df = pd.DataFrame([no_matched_info], columns = cols)
                if no_match_info_summary.empty: 
                    no_match_info_summary = no_match_df
                else: 
                    no_match_info_summary = pd.concat([no_match_info_summary, no_match_df])
                continue 

            for seg_match in potential_seg_matches: 
                curr_seg_info = match_img_seg_df[match_img_seg_df["SegSeriesInstanceUID"] == seg_match]

                img_locs, seg_locs = get_nifti_locs(nifti_idx_path, curr_seg_info)

                #Have to enter this loop since there are scenarios where the nifti files got converted to be mapped to the same
                #segmentation series instance UIDs 
                for idx, measurement in curr_measurements.iterrows():
                    #Check to see if these coordinates have already been checked though for this patient (handles annotation duplicates)
                    if not match_info_summary.empty: 
                        in_matches = curr_measurements["LongAxisCoords"].values[0] in match_info_summary["AnnLongAxisCoordinates"].values.tolist() and curr_measurements["AnnPatientID"].values[0] in match_info_summary["PatientID"].values.tolist()
                        if in_matches: 
                            #A duplicate measurement was found. Going to skip this measurement for this slice. 
                            logger.info("Annotation series instance UID: %s measurement for patient %s is a duplicate of an annotation which has already been matched.", ann_seriesInstUID, curr_measurements["AnnPatientID"].values[0])
                            logger.info("Long axis coordiantes duplicated: %s", curr_measurements["LongAxisCoords"].values[0])
                            continue 

                    if not no_match_info_summary.empty: 
                        in_no_matches = curr_measurements["LongAxisCoords"].values[0] in no_match_info_summary["AnnLongAxisCoordinates"].values.tolist() and curr_measurements["AnnPatientID"].values[0] in no_match_info_summary["PatientID"].values.tolist()
                        if in_no_matches: 
                            #A duplicate measurement was found. Going to skip this measurement for this slice. 
                            logger.info("Annotation series instance UID: %s measurement for patient %s is a duplicate of an annotation already searched through and determined to have no match.", ann_seriesInstUID, curr_measurements["AnnPatientID"].values[0])
                            logger.info("Long axis coordiantes duplicated: %s", curr_measurements["LongAxisCoords"].values[0])
                            continue 
                        
                    measurement_df = pd.DataFrame(measurement).transpose()
                    if img_locs.empty or seg_locs.empty: 
                        #If there was no matching nifti files, count as a no match
                        no_matched_info = [ann_dicom_info["PatientID"], 
                                        ann_dicom_info["StudyInstanceUID"], 
                                        img_ann_info["ImgSeriesInstanceUID"].values[0], 
                                        ann_refSeriesUID,  
                                        seg_dicom_info["ReferencedSeriesUID"], #Assumes that all potential seg matches have the same ref image
                                        ann_dicom_info["SeriesInstanceUID"], 
                                        potential_seg_matches, 
                                        refSOPUID, 
                                        measurement_df["LongAxisMeasurement"].values[0],
                                        measurement_df["LongAxisMeasureType"].values[0], 
                                        measurement_df["LongAxisUnit"].values[0],
                                        measurement_df["LongAxisCoords"].values[0],
                                        measurement_df["ShortAxisMeasurement"].values[0], 
                                        measurement_df["ShortAxisMeasureType"].values[0], 
                                        measurement_df["ShortAxisUnit"].values[0],
                                        measurement_df["ShortAxisCoords"].values[0], 
                                        measurement_df["AnnPOI"].values[0],
                                        img_ann_info["ImgModality"].values[0], 
                                        ann_dicom_info["Modality"], 
                                        seg_dicom_info["Modality"],
                                        img_subseries, 
                                        img_ann_info["ImgLocation"].values[0], 
                                        img_ann_info["AnnLocation"].values[0],
                                        filename,
                                        None,
                                        None,
                                        None]
                            
                        no_match_df = pd.DataFrame([no_matched_info], columns = cols)

                        if no_match_info_summary.empty: 
                            no_match_info_summary = no_match_df
                        else: 
                            no_match_info_summary = pd.concat([no_match_info_summary, no_match_df])
                        continue 

                    for i in range(len(seg_locs)): 
                        for j in range(len(img_locs)):
                            seg_loc = seg_locs.iloc[i]
                            img_loc = img_locs.iloc[j]
                            is_in_seg = confirm_ann_seg_match(measurement_df, img_loc, seg_loc, dicom_info_dict, img_subseries, img_out_path)
                            if is_in_seg: 
                                matched_info = [ann_dicom_info["PatientID"], 
                                                ann_dicom_info["StudyInstanceUID"], 
                                                img_ann_info["ImgSeriesInstanceUID"].values[0], 
                                                ann_refSeriesUID,  
                                                seg_dicom_info["ReferencedSeriesUID"], #Assumes that all potential seg matches have the same ref image
                                                ann_dicom_info["SeriesInstanceUID"], 
                                                seg_match,
                                                refSOPUID, 
                                                measurement_df["LongAxisMeasurement"].values[0],
                                                measurement_df["LongAxisMeasureType"].values[0], 
                                                measurement_df["LongAxisUnit"].values[0],
                                                measurement_df["LongAxisCoords"].values[0],
                                                measurement_df["ShortAxisMeasurement"].values[0], 
                                                measurement_df["ShortAxisMeasureType"].values[0], 
                                                measurement_df["ShortAxisUnit"].values[0],
                                                measurement_df["ShortAxisCoords"].values[0], 
                                                measurement_df["AnnPOI"].values[0],
                                                img_ann_info["ImgModality"].values[0], 
                                                ann_dicom_info["Modality"], 
                                                seg_dicom_info["Modality"],
                                                img_subseries, 
                                                img_ann_info["ImgLocation"].values[0], 
                                                img_ann_info["AnnLocation"].values[0],
                                                filename,
                                                curr_seg_info["SegLocation"].values[0],
                                                j, #Image NIFTI path
                                                i  #Segmentation NIFTI path
                                            ]
                    
                                match_info_df = pd.DataFrame([matched_info], columns = cols)
                                if match_info_summary.empty:
                                    match_info_summary = match_info_df
                                else:
                                    match_info_summary = pd.concat([match_info_summary, match_info_df])

                            else: 
                                no_matched_info = [ann_dicom_info["PatientID"], 
                                        ann_dicom_info["StudyInstanceUID"], 
                                        img_ann_info["ImgSeriesInstanceUID"].values[0], 
                                        ann_refSeriesUID,  
                                        seg_dicom_info["ReferencedSeriesUID"], #Assumes that all potential seg matches have the same ref image
                                        ann_dicom_info["SeriesInstanceUID"], 
                                        potential_seg_matches, 
                                        refSOPUID, 
                                        measurement_df["LongAxisMeasurement"].values[0],
                                        measurement_df["LongAxisMeasureType"].values[0], 
                                        measurement_df["LongAxisUnit"].values[0],
                                        measurement_df["LongAxisCoords"].values[0],
                                        measurement_df["ShortAxisMeasurement"].values[0], 
                                        measurement_df["ShortAxisMeasureType"].values[0], 
                                        measurement_df["ShortAxisUnit"].values[0],
                                        measurement_df["ShortAxisCoords"].values[0], 
                                        measurement_df["AnnPOI"].values[0],
                                        img_ann_info["ImgModality"].values[0], 
                                        ann_dicom_info["Modality"], 
                                        seg_dicom_info["Modality"],
                                        img_subseries, 
                                        img_ann_info["ImgLocation"].values[0], 
                                        img_ann_info["AnnLocation"].values[0],
                                        filename,
                                        None,
                                        None,
                                        None]
                            
                                no_match_df = pd.DataFrame([no_matched_info], columns = cols)

                                if no_match_info_summary.empty: 
                                    no_match_info_summary = no_match_df
                                else: 
                                    no_match_info_summary = pd.concat([no_match_info_summary, no_match_df])

    return match_info_summary, no_match_info_summary

@click.command()
@click.option('--idx_dicom_file', help = 'Path and name of DICOM index.csv file created by med-imagetools')
@click.option('--idx_nifti_file', help = 'Path and name of mit_DATASET_index.csv file creaded by med-imagetools')
@click.option('--crawl_db_file', help = 'Path and name of crawl_db.json file created by med-imagetools')
@click.option('--dataset_path', help = 'Path containing images folder for annotations, imaging, and segmentations. Used to get segmentations')
@click.option('--log_path', help = 'Path for log file to be created')
@click.option('--df_out_path', help = 'Destination for outputted csv files')
@click.option('--plot_out_path', help = 'Destination for outputted annotation-image-segmentation overlay plots')
@click.option('--get_intermediate_dfs', default = False, help = 'Determines if you output the annotation-to-image and image-to-segmentation matching files. Default False.')
def run_matching(idx_dicom_file: str,
                 idx_nifti_file: str,
                 crawl_db_file: str, 
                 ann_dcm_path: str, 
                 dataset_path: str, 
                 log_path: str, 
                 df_out_path: str, 
                 plot_out_path: str, 
                 get_intermediate_dfs: bool
                 ): 
    
    log_path = Path(log_path)
    idx_dicom_file = Path(idx_dicom_file)
    idx_nifti_file = Path(idx_nifti_file)
    crawl_db_file = Path(crawl_db_file)
    ann_dcm_path = Path(ann_dcm_path)
    dataset_path = Path(dataset_path)
    df_out_path = Path(df_out_path)
    plot_out_path = Path(plot_out_path)

    logging.basicConfig(filename=log_path / "match_ann_to_seg.log", encoding='utf-8', level=logging.DEBUG)

    index_df = pd.read_csv(idx_dicom_file)

    matched_ann_img_df = match_ann_to_image(index_df) 

    matched_img_seg_df = match_img_to_seg(index_df, matched_ann_img_df) 

    if not df_out_path.exists():
        Path(df_out_path).mkdir(parents=True, exist_ok = True)

    if not plot_out_path.exists(): 
        Path(plot_out_path).mkdir(parents=True, exist_ok = True)

    if get_intermediate_dfs: 
        matched_ann_img_df.to_csv(df_out_path / "matching_ann_to_img.csv", index = False)
        matched_img_seg_df.to_csv(df_out_path / "matching_img_to_seg.csv", index = False)

    with open(crawl_db_file, 'r') as file: 
        dicom_data_json = file.read()
        dicom_data_dict = json.loads(dicom_data_json)

        # matched_ann_seg, no_match_ann_seg = match_ann_to_seg(matched_ann_img_df, matched_img_seg_df, dicom_data_dict, ann_dcm_path, dataset_path)
        matched_ann_seg, no_match_ann_seg = match_ann_to_seg(match_ann_img_df = matched_ann_img_df, 
                                                             match_img_seg_df = matched_img_seg_df, 
                                                             dicom_info_dict = dicom_data_dict, 
                                                             nifti_idx_path = idx_nifti_file, 
                                                             ann_seg_dicom_path = dataset_path, 
                                                             img_out_path = plot_out_path)
        matched_ann_seg.to_csv(df_out_path / "matching_ann_to_seg.csv", index = False)
        no_match_ann_seg.to_csv(df_out_path / "no_matching_ann_to_seg.csv", index = False)

        file.close()
    
if __name__ == '__main__': 
    logger = logging.getLogger(__name__)
    logging.basicConfig(filename = dirs.LOGS / "match_no_match_ann_img_seg_OCTANE.log", encoding='utf-8', level=logging.DEBUG)
    
    idx_dicom_path = dirs.RAWDATA / "PMCC_OCTANE/.imgtools/images/index.csv"
    idx_nifti_path = dirs.PROCDATA / "PMCC_OCTANE/images/mit_OCTANE/mit_OCTANE_index.csv"
    dicom_data_path = dirs.RAWDATA / "PMCC_OCTANE/.imgtools/images/crawl_db.json"
    ann_seg_data_path = dirs.RAWDATA / "PMCC_OCTANE"
    out_path = dirs.PROCDATA / "PMCC_OCTANE/metadata/annotation_seg_matching"
    img_out_path = dirs.RESULTS / "PMCC_OCTANE/visualization/annotation_seg_matching"

    # out_path = Path("/home/bhkuser/bhklab/kaitlyn/aaura_paper0/workflow/testing/matching_ann_to_mask")
    # img_out_path = Path("/home/bhkuser/bhklab/kaitlyn/aaura_paper0/workflow/testing/matching_ann_to_mask/plots")

    if not out_path.exists():
        Path(out_path).mkdir(parents=True, exist_ok = True)

    if not img_out_path.exists(): 
        Path(img_out_path).mkdir(parents=True, exist_ok = True)
    index_dicom_df = pd.read_csv(idx_dicom_path)
    
    matched_ann_img_df = match_ann_to_image(index_dicom_df) 
    matched_img_seg_df = match_img_to_seg(index_dicom_df, matched_ann_img_df)


    with open(dicom_data_path, 'r') as file: 
        dicom_data_json = file.read()
        dicom_data_dict = json.loads(dicom_data_json)

        matched_ann_seg, no_match_ann_seg = match_ann_to_seg(match_ann_img_df = matched_ann_img_df, 
                                                             match_img_seg_df = matched_img_seg_df, 
                                                             dicom_info_dict = dicom_data_dict, 
                                                             nifti_idx_path = idx_nifti_path, 
                                                             ann_seg_dicom_path = ann_seg_data_path,  
                                                             img_out_path = img_out_path)
        matched_ann_seg.to_csv(out_path / "matching_ann_to_seg.csv", index = False)
        no_match_ann_seg.to_csv(out_path / "no_match_ann_to_seg.csv", index = False)

        file.close()
    
    #run_matching()