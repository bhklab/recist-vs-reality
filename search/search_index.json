{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"RECIST vs Reality Authors: Caryn Geady , Katy Scott Contact: bhklab.caryngeady@gmail.com Description: Code for RECIST to Reality manuscript. Set Up Prerequisites Pixi is required to run this project. If you haven't installed it yet, follow these instructions Installation Clone this repository to your local machine Navigate to the project directory Set up the environment using Pixi: pixi install Documentation Click here to view the full documentation.","title":"Home"},{"location":"#recist-vs-reality","text":"Authors: Caryn Geady , Katy Scott Contact: bhklab.caryngeady@gmail.com Description: Code for RECIST to Reality manuscript.","title":"RECIST vs Reality"},{"location":"#set-up","text":"","title":"Set Up"},{"location":"#prerequisites","text":"Pixi is required to run this project. If you haven't installed it yet, follow these instructions","title":"Prerequisites"},{"location":"#installation","text":"Clone this repository to your local machine Navigate to the project directory Set up the environment using Pixi: pixi install","title":"Installation"},{"location":"#documentation","text":"Click here to view the full documentation.","title":"Documentation"},{"location":"data_sources/","text":"Data Sources External Data Sources CPTAC-HNSCC Name : The Clinical Proteomic Tumor Analysis Consortium Head and Neck Squamous Cell Carcinoma Collection Version/Date : Version 14 or 15? URL : https://www.cancerimagingarchive.net/collection/cptac-hnscc/ Access Method : NBIA Data Retriever Access Date : 2024-03-29 Data Format : DICOM-CT, DICOM-RTSTRUCT Citation : National Cancer Institute Clinical Proteomic Tumor Analysis Consortium (CPTAC). (2018). The Clinical Proteomic Tumor Analysis Consortium Head and Neck Squamous Cell Carcinoma Collection (CPTAC-HNSCC) (Version 19) [dataset]. The Cancer Imaging Archive. https://doi.org/10.7937/k9/tcia.2018.uw45nh81 License : TCIA Restricted License Data Types : Images: CT, RTSTRUCT Sample Size Selected : TBD PatientIDs : C3N-00297 C3N-00498 C3N-00828 C3N-01620 C3N-01752 C3N-01754 C3N-01757 C3N-01943 C3N-01948 Crowds-Cure-2018 Name : Crowds Cure Cancer: Data collected at the RSNA 2018 annual meeting Version/Date : Version 1: Updated 2019/05/30 URL : https://www.cancerimagingarchive.net/analysis-result/crowds-cure-2018/ Access Method : NBIA Data Retriever Access Date : 2025-03-26 Data Format : DICOM-SR Citation : Urban, T., Ziegler, E., Pieper, S., Kirby, J., Rukas, D., Beardmore, B., Somarouthu, B., Ozkan, E., Lelis, G., Fevrier-Sullivan, B., Nandekar, S., Beers, A., Jaffe, C., Freymann, J., Clunie, D., Harris, G. J., & Kalpathy-Cramer, J. (2019). Crowds Cure Cancer: Crowdsourced data collected at the RSNA 2018 annual meeting [Data set]. The Cancer Imaging Archive. https://doi.org/10.7937/TCIA.2019.yk0gm1eb License : CC BY 3.0 Data Types : Annotations: Structured Reports containing 2D RECIST measurements Sample Size Selected : TBD Overview This section should document all data sources used in your project. Proper documentation ensures reproducibility and helps others understand your research methodology. How to Document Your Data For each data source, include the following information: 1. External Data Sources Name : Official name of the dataset Version/Date : Version number or access date URL : Link to the data source Access Method : How the data was obtained (direct download, API, etc.) Access Date : When the data was accessed/retrieved Data Format : Format of the data (FASTQ, DICOM, CSV, etc.) Citation : Proper academic citation if applicable License : Usage restrictions and attribution requirements Example: ## TCGA RNA-Seq Data - **Name**: The Cancer Genome Atlas RNA-Seq Data - **Version**: Data release 28.0 - March 2021 - **URL**: https://portal.gdc.cancer.gov/ - **Access Method**: GDC Data Transfer Tool - **Access Date**: 2021-03-15 - **Citation**: The Cancer Genome Atlas Network. (2012). Comprehensive molecular portraits of human breast tumours. Nature, 490(7418), 61-70. - **License**: [NIH Genomic Data Sharing Policy](https://sharing.nih.gov/genomic-data-sharing-policy) 2. Internal/Generated Data Name : Descriptive name of the dataset Creation Date : When the data was generated Creation Method : Brief description of how the data was created Input Data : What source data was used Processing Scripts : References to scripts/Github Repo used to generate this data Example: ## Processed RNA-Seq Data - **Name**: Processed RNA-Seq Data for TCGA-BRCA - **Creation Date**: 2021-04-01 - **Creation Method**: Processed using kallisto and DESeq2 - **Input Data**: FASTQ Data obtained from the SRA database - **Processing Scripts**: [GitHub Repo](https://github.com/tcga-brca-rnaseq) 3. Data Dictionary For complex datasets, include a data dictionary that explains: Column Name Data Type Description Units Possible Values patient_id string Unique patient identifier N/A TCGA-XX-XXXX format age integer Patient age at diagnosis years 18-100 expression float Gene expression value TPM Any positive value Best Practices Store raw data in data/rawdata/ and never modify it Store processed data in data/procdata/ and all code used to generate it should be in workflow/scripts/ Document all processing steps Track data provenance (where data came from and how it was modified) Respect data usage agreements and licenses! This is especially important for data that should not be shared publicly","title":"Data Sources"},{"location":"data_sources/#data-sources","text":"","title":"Data Sources"},{"location":"data_sources/#external-data-sources","text":"","title":"External Data Sources"},{"location":"data_sources/#cptac-hnscc","text":"Name : The Clinical Proteomic Tumor Analysis Consortium Head and Neck Squamous Cell Carcinoma Collection Version/Date : Version 14 or 15? URL : https://www.cancerimagingarchive.net/collection/cptac-hnscc/ Access Method : NBIA Data Retriever Access Date : 2024-03-29 Data Format : DICOM-CT, DICOM-RTSTRUCT Citation : National Cancer Institute Clinical Proteomic Tumor Analysis Consortium (CPTAC). (2018). The Clinical Proteomic Tumor Analysis Consortium Head and Neck Squamous Cell Carcinoma Collection (CPTAC-HNSCC) (Version 19) [dataset]. The Cancer Imaging Archive. https://doi.org/10.7937/k9/tcia.2018.uw45nh81 License : TCIA Restricted License Data Types : Images: CT, RTSTRUCT Sample Size Selected : TBD PatientIDs : C3N-00297 C3N-00498 C3N-00828 C3N-01620 C3N-01752 C3N-01754 C3N-01757 C3N-01943 C3N-01948","title":"CPTAC-HNSCC"},{"location":"data_sources/#crowds-cure-2018","text":"Name : Crowds Cure Cancer: Data collected at the RSNA 2018 annual meeting Version/Date : Version 1: Updated 2019/05/30 URL : https://www.cancerimagingarchive.net/analysis-result/crowds-cure-2018/ Access Method : NBIA Data Retriever Access Date : 2025-03-26 Data Format : DICOM-SR Citation : Urban, T., Ziegler, E., Pieper, S., Kirby, J., Rukas, D., Beardmore, B., Somarouthu, B., Ozkan, E., Lelis, G., Fevrier-Sullivan, B., Nandekar, S., Beers, A., Jaffe, C., Freymann, J., Clunie, D., Harris, G. J., & Kalpathy-Cramer, J. (2019). Crowds Cure Cancer: Crowdsourced data collected at the RSNA 2018 annual meeting [Data set]. The Cancer Imaging Archive. https://doi.org/10.7937/TCIA.2019.yk0gm1eb License : CC BY 3.0 Data Types : Annotations: Structured Reports containing 2D RECIST measurements Sample Size Selected : TBD","title":"Crowds-Cure-2018"},{"location":"data_sources/#overview","text":"This section should document all data sources used in your project. Proper documentation ensures reproducibility and helps others understand your research methodology.","title":"Overview"},{"location":"data_sources/#how-to-document-your-data","text":"For each data source, include the following information:","title":"How to Document Your Data"},{"location":"data_sources/#1-external-data-sources","text":"Name : Official name of the dataset Version/Date : Version number or access date URL : Link to the data source Access Method : How the data was obtained (direct download, API, etc.) Access Date : When the data was accessed/retrieved Data Format : Format of the data (FASTQ, DICOM, CSV, etc.) Citation : Proper academic citation if applicable License : Usage restrictions and attribution requirements Example: ## TCGA RNA-Seq Data - **Name**: The Cancer Genome Atlas RNA-Seq Data - **Version**: Data release 28.0 - March 2021 - **URL**: https://portal.gdc.cancer.gov/ - **Access Method**: GDC Data Transfer Tool - **Access Date**: 2021-03-15 - **Citation**: The Cancer Genome Atlas Network. (2012). Comprehensive molecular portraits of human breast tumours. Nature, 490(7418), 61-70. - **License**: [NIH Genomic Data Sharing Policy](https://sharing.nih.gov/genomic-data-sharing-policy)","title":"1. External Data Sources"},{"location":"data_sources/#2-internalgenerated-data","text":"Name : Descriptive name of the dataset Creation Date : When the data was generated Creation Method : Brief description of how the data was created Input Data : What source data was used Processing Scripts : References to scripts/Github Repo used to generate this data Example: ## Processed RNA-Seq Data - **Name**: Processed RNA-Seq Data for TCGA-BRCA - **Creation Date**: 2021-04-01 - **Creation Method**: Processed using kallisto and DESeq2 - **Input Data**: FASTQ Data obtained from the SRA database - **Processing Scripts**: [GitHub Repo](https://github.com/tcga-brca-rnaseq)","title":"2. Internal/Generated Data"},{"location":"data_sources/#3-data-dictionary","text":"For complex datasets, include a data dictionary that explains: Column Name Data Type Description Units Possible Values patient_id string Unique patient identifier N/A TCGA-XX-XXXX format age integer Patient age at diagnosis years 18-100 expression float Gene expression value TPM Any positive value","title":"3. Data Dictionary"},{"location":"data_sources/#best-practices","text":"Store raw data in data/rawdata/ and never modify it Store processed data in data/procdata/ and all code used to generate it should be in workflow/scripts/ Document all processing steps Track data provenance (where data came from and how it was modified) Respect data usage agreements and licenses! This is especially important for data that should not be shared publicly","title":"Best Practices"},{"location":"usage/","text":"Usage Guide Project Configuration Each dataset needs a configuration YAML file with the following settings filled in DATA_SOURCE: \"\" # where the data came from, will be used for data organization DATASET_NAME: \"\" # the name of the dataset , will be use for data organization ### MED-IMAGETOOLS settings MIT: MODALITIES: # Modalities to process with autopipeline image: CT mask: RTSTRUCT ROI_STRATEGY: MERGE # How to handle multiple ROI matches ROI_MATCH_MAP: # Matching map for ROIs in dataset (use if you only want to process some of the masks in a segmentation) KEY:ROI_NAME # NOTE: there can be no spaces in KEY:ROI_NAME The file should be saved in the config directory and named {DATASET_NAME}.yaml . Data Setup The following sections describe how to set up the data you wish to process with this pipeline following the BHKLab Data Management Protocol (DMP). This will ensure data remains separate from the project directory and accessible to other users. Raw Data Set up a separate main data directory outside of the project directory. We'll call this Datasets . In Datasets , set up a directory for the dataset you wish to process as follows: Datasets |---- {DATASET_SOURCE}_{DATASET_NAME} |-- clinical | `-- {Clinical Data File}.csv OR {Clinical Data File}.xlsx `-- images |-- {DATASET_NAME} | |-- {PatientID} | | `-- {StudyUID} | | |-- {Image DICOM directory} | | | |-- 1-01.dcm | | | |-- ... | | | |-- 1-N.dcm | | |-- {Mask DICOM directory} | | | `-- 1-01.dcm | |-- {PatientID} | |-- ... | `-- {PatientID} `-- annotations `-- {DATASET_NAME} |-- DICOM-SR_annotation_file.dcm |-- DICOM-SR_annotation_file.dcm `-- DICOM-SR_annotation_file.dcm Image directory structure may vary depending on the source. This example is based on the structure setup by TCIA when downloading with a manifest file. However, for the pipeline to run correctly, images/{DATASET_NAME} must exist in the {DATASET_SOURCE}_{DATASET_NAME} directory. Everything within {DATASET_NAME} may vary though. !!! note \"BHKLab DMP Setup\" If using the BHKLab DMP, the Datasets directory will be structured with rawdata/{DiseaseRegion}/{DATASET_SOURCE}_{DATASET_NAME} . In the next step, you can create the symbolic link starting from {DATASET_SOURCE}_{DATASET_NAME} . Once this data directory is setup, run the following in a terminal from the main directory of the project. ln -s /path/to/Datasets/{DATASET_SOURCE}_{DATASET_NAME} data/rawdata This will create a symbolic link to your dataset in the Datasets directory. You can confirm this worked by running: ls -l data/rawdata and you should see, total 5 -rw-rw-r-- 1 bhkuser root 1395 Jun 4 15:21 README.md lrwxrwxrwx 1 bhkuser root 80 Jun 4 15:46 {DATASET_SOURCE}_{DATASET_NAME} -> /path/to/Datasets/{DATASET_SOURCE}_{DATASET_NAME} Now, document the dataset you've added on the Data Sources page following the provided template. Processed Data If you wish to use the BHKLab DMP strategy, follow the process below. Create a processed data directory for your dataset in the external Datasets directory as follows: mkdir /path/to/Datasets/procdata/{DiseaseRegion}/{DATASET_SOURCE}_{DATASET_NAME} Note : the Disease Region must match what is in the rawdata path to the dataset. Now you can create a symbolic link to this directory in the project directory, like we did for the raw data. ln -s /path/to/Datasets/procdata/{DiseaseRegion}/{DATASET_SOURCE}_{DATASET_NAME} data/procdata Results TODO:: describe results directory setup Running Your Analysis 1. Running Med-ImageTools The first step in the pipeline is to run Med-ImageTools index and autopipeline to organize and process the image and mask data. Requirements: 1. You've set up a dataset config yaml file as described above. 2. You've set up the symbolic links for the dataset in both rawdata and procdata From the home project directory, run the following: pixi run mit config/{DATASET_NAME}.yaml This will generate NiFTi files for each image and it's corresponding mask, where the masks will be named KEY__[ROI_NAME] . The output format should be as follows: ``bash data -- procdata -- {DATASET_SOURCE}_{DATASET_NAME} -- images -- mit_{DATASET_NAME} -- {PatientID} {SampleNumber} |-- {ImageModality} {SeriesInstanceUID} | -- {ImageModality}.nii.gz -- {SegmentationModality}_{SeriesInstanceUID} `-- {KEY}__[{ROI_name}].nii.gz","title":"Usage"},{"location":"usage/#usage-guide","text":"","title":"Usage Guide"},{"location":"usage/#project-configuration","text":"Each dataset needs a configuration YAML file with the following settings filled in DATA_SOURCE: \"\" # where the data came from, will be used for data organization DATASET_NAME: \"\" # the name of the dataset , will be use for data organization ### MED-IMAGETOOLS settings MIT: MODALITIES: # Modalities to process with autopipeline image: CT mask: RTSTRUCT ROI_STRATEGY: MERGE # How to handle multiple ROI matches ROI_MATCH_MAP: # Matching map for ROIs in dataset (use if you only want to process some of the masks in a segmentation) KEY:ROI_NAME # NOTE: there can be no spaces in KEY:ROI_NAME The file should be saved in the config directory and named {DATASET_NAME}.yaml .","title":"Project Configuration"},{"location":"usage/#data-setup","text":"The following sections describe how to set up the data you wish to process with this pipeline following the BHKLab Data Management Protocol (DMP). This will ensure data remains separate from the project directory and accessible to other users.","title":"Data Setup"},{"location":"usage/#raw-data","text":"Set up a separate main data directory outside of the project directory. We'll call this Datasets . In Datasets , set up a directory for the dataset you wish to process as follows: Datasets |---- {DATASET_SOURCE}_{DATASET_NAME} |-- clinical | `-- {Clinical Data File}.csv OR {Clinical Data File}.xlsx `-- images |-- {DATASET_NAME} | |-- {PatientID} | | `-- {StudyUID} | | |-- {Image DICOM directory} | | | |-- 1-01.dcm | | | |-- ... | | | |-- 1-N.dcm | | |-- {Mask DICOM directory} | | | `-- 1-01.dcm | |-- {PatientID} | |-- ... | `-- {PatientID} `-- annotations `-- {DATASET_NAME} |-- DICOM-SR_annotation_file.dcm |-- DICOM-SR_annotation_file.dcm `-- DICOM-SR_annotation_file.dcm Image directory structure may vary depending on the source. This example is based on the structure setup by TCIA when downloading with a manifest file. However, for the pipeline to run correctly, images/{DATASET_NAME} must exist in the {DATASET_SOURCE}_{DATASET_NAME} directory. Everything within {DATASET_NAME} may vary though. !!! note \"BHKLab DMP Setup\" If using the BHKLab DMP, the Datasets directory will be structured with rawdata/{DiseaseRegion}/{DATASET_SOURCE}_{DATASET_NAME} . In the next step, you can create the symbolic link starting from {DATASET_SOURCE}_{DATASET_NAME} . Once this data directory is setup, run the following in a terminal from the main directory of the project. ln -s /path/to/Datasets/{DATASET_SOURCE}_{DATASET_NAME} data/rawdata This will create a symbolic link to your dataset in the Datasets directory. You can confirm this worked by running: ls -l data/rawdata and you should see, total 5 -rw-rw-r-- 1 bhkuser root 1395 Jun 4 15:21 README.md lrwxrwxrwx 1 bhkuser root 80 Jun 4 15:46 {DATASET_SOURCE}_{DATASET_NAME} -> /path/to/Datasets/{DATASET_SOURCE}_{DATASET_NAME} Now, document the dataset you've added on the Data Sources page following the provided template.","title":"Raw Data"},{"location":"usage/#processed-data","text":"If you wish to use the BHKLab DMP strategy, follow the process below. Create a processed data directory for your dataset in the external Datasets directory as follows: mkdir /path/to/Datasets/procdata/{DiseaseRegion}/{DATASET_SOURCE}_{DATASET_NAME} Note : the Disease Region must match what is in the rawdata path to the dataset. Now you can create a symbolic link to this directory in the project directory, like we did for the raw data. ln -s /path/to/Datasets/procdata/{DiseaseRegion}/{DATASET_SOURCE}_{DATASET_NAME} data/procdata","title":"Processed Data"},{"location":"usage/#results","text":"TODO:: describe results directory setup","title":"Results"},{"location":"usage/#running-your-analysis","text":"","title":"Running Your Analysis"},{"location":"usage/#1-running-med-imagetools","text":"The first step in the pipeline is to run Med-ImageTools index and autopipeline to organize and process the image and mask data. Requirements: 1. You've set up a dataset config yaml file as described above. 2. You've set up the symbolic links for the dataset in both rawdata and procdata From the home project directory, run the following: pixi run mit config/{DATASET_NAME}.yaml This will generate NiFTi files for each image and it's corresponding mask, where the masks will be named KEY__[ROI_NAME] . The output format should be as follows: ``bash data -- procdata -- {DATASET_SOURCE}_{DATASET_NAME} -- images -- mit_{DATASET_NAME} -- {PatientID} {SampleNumber} |-- {ImageModality} {SeriesInstanceUID} | -- {ImageModality}.nii.gz -- {SegmentationModality}_{SeriesInstanceUID} `-- {KEY}__[{ROI_name}].nii.gz","title":"1. Running Med-ImageTools"},{"location":"devnotes/devnotes_caryn/","text":"Developer Notes - Caryn Purpose of This Section This section is for documenting technical decisions, challenges, and solutions encountered during your project. These notes are valuable for: Future you (who will forget why certain decisions were made) Collaborators who join the project later People coming from your publication who want to reproduce your work Anyone who might want to extend your research What to Document Design Decisions Document important decisions about your project's architecture, algorithms, or methodologies: ## Choice of RNA-Seq Analysis Pipeline [2025-04-25] We chose the kallisto over STAR pipeline for the following reasons: 1. The CCLE dataset is very large, and kallisto is faster for quantifying large datasets 2. GDSC used kallisto, so we can compare our results with theirs Technical Challenges Record significant problems you encountered and how you solved them ## Sample Name Format Issue [2025-04-25] We encountered a problem with sample name formats between the CCLE and GDSC datasets. The CCLE dataset uses \"BRCA-XX-XXXX\" format, while the GDSC dataset uses \"BRCA-XX-XXXX-XX\". We had to write a script to remove the last two characters from the sample names in the GDSC dataset. Dependencies and Environment Document specific version requirements or compatibility issues: ## Critical Version Dependencies [2025-04-25] SimpleITK 2.4.1 introduced a bug that flips images, so we froze version 2.4.0 Best Practices Date your entries when appropriate Link to relevant code files or external resources Include small code snippets when helpful Note alternatives you considered and why they were rejected Document failed approaches to prevent others from repeating mistakes Update notes when major changes are made to the approach","title":"Caryn"},{"location":"devnotes/devnotes_caryn/#developer-notes-caryn","text":"","title":"Developer Notes - Caryn"},{"location":"devnotes/devnotes_caryn/#purpose-of-this-section","text":"This section is for documenting technical decisions, challenges, and solutions encountered during your project. These notes are valuable for: Future you (who will forget why certain decisions were made) Collaborators who join the project later People coming from your publication who want to reproduce your work Anyone who might want to extend your research","title":"Purpose of This Section"},{"location":"devnotes/devnotes_caryn/#what-to-document","text":"","title":"What to Document"},{"location":"devnotes/devnotes_caryn/#design-decisions","text":"Document important decisions about your project's architecture, algorithms, or methodologies: ## Choice of RNA-Seq Analysis Pipeline [2025-04-25] We chose the kallisto over STAR pipeline for the following reasons: 1. The CCLE dataset is very large, and kallisto is faster for quantifying large datasets 2. GDSC used kallisto, so we can compare our results with theirs","title":"Design Decisions"},{"location":"devnotes/devnotes_caryn/#technical-challenges","text":"Record significant problems you encountered and how you solved them ## Sample Name Format Issue [2025-04-25] We encountered a problem with sample name formats between the CCLE and GDSC datasets. The CCLE dataset uses \"BRCA-XX-XXXX\" format, while the GDSC dataset uses \"BRCA-XX-XXXX-XX\". We had to write a script to remove the last two characters from the sample names in the GDSC dataset.","title":"Technical Challenges"},{"location":"devnotes/devnotes_caryn/#dependencies-and-environment","text":"Document specific version requirements or compatibility issues: ## Critical Version Dependencies [2025-04-25] SimpleITK 2.4.1 introduced a bug that flips images, so we froze version 2.4.0","title":"Dependencies and Environment"},{"location":"devnotes/devnotes_caryn/#best-practices","text":"Date your entries when appropriate Link to relevant code files or external resources Include small code snippets when helpful Note alternatives you considered and why they were rejected Document failed approaches to prevent others from repeating mistakes Update notes when major changes are made to the approach","title":"Best Practices"},{"location":"devnotes/devnotes_katy/","text":"Developer Notes - Katy SR Exploration [2025-06-04] SR's can be read by MIT index, but it looks like at least the CCC HNSCC ones don't have a ReferenceSeriesUID From Caryn's sr_testing.py script, there is a ReferencedSOPInstanceUID, which means we can determine the slice, just gotta figure out in what CT","title":"Katy"},{"location":"devnotes/devnotes_katy/#developer-notes-katy","text":"","title":"Developer Notes - Katy"},{"location":"devnotes/devnotes_katy/#sr-exploration","text":"","title":"SR Exploration"},{"location":"devnotes/devnotes_katy/#2025-06-04","text":"SR's can be read by MIT index, but it looks like at least the CCC HNSCC ones don't have a ReferenceSeriesUID From Caryn's sr_testing.py script, there is a ReferencedSOPInstanceUID, which means we can determine the slice, just gotta figure out in what CT","title":"[2025-06-04]"}]}